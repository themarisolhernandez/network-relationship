{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849aa3b3",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730a973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "import pathlib\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import re\n",
    "#from fuzzywuzzy import fuzz\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "import io\n",
    "import os\n",
    "\n",
    "desired_width = 320\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "pd.set_option(\"display.width\", desired_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a01ca2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== START LOGGER =====\n",
    "logger = logging.getLogger(__name__)\n",
    "root_logger = logging.getLogger()\n",
    "root_logger.setLevel(logging.INFO)\n",
    "sh = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "sh.setFormatter(formatter)\n",
    "root_logger.addHandler(sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4dd816",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "In this step, we use the download URL to download the paper itself and save it using the clean title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3d8bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = pd.read_csv(\"outputs/lda_df.csv\", index_col=0)\n",
    "path = '/Users/marisolhernandez/Desktop/SKAEL/Network Diagram/files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3d82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(download_url, filename):\n",
    "    response = urllib.request.urlopen(download_url)    \n",
    "    file = open(path + filename + \".pdf\", 'wb')\n",
    "    file.write(response.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0893416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files\n",
    "for i, row in lda_df.iterrows():\n",
    "    title = row['clean title']\n",
    "    #download_url = row['url']\n",
    "    \n",
    "    try:\n",
    "        #download_file(download_url, title)\n",
    "        lda_df.loc[[i],'filename'] = title + '.pdf'\n",
    "        \n",
    "    except:\n",
    "        lda_df.loc[[i],'filename'] = ''\n",
    "        print('Failed\\nindex: ' + str(i) + '\\ntitle: ' + str(row['clean title']) + '\\nurl: ' + str(row['url']) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b75e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing value\n",
    "lda_df = lda_df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476fb102",
   "metadata": {},
   "source": [
    "## Add Citations Data\n",
    "We open and read each paper searching for the titles and authors of the remaining papers. If the title or author of another paper is found, then a connection is created and established between the two papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0896c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add citation data to the DataFrame\n",
    "cite_links = list()\n",
    "counter = 0\n",
    "cited_by = {str(i): [] for i in range(len(lda_df))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd116da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsrcmgr = PDFResourceManager()\n",
    "retstr = io.StringIO()\n",
    "codec = 'utf-8'\n",
    "laparams = LAParams()\n",
    "device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "for i, row in lda_df.iterrows():\n",
    "    try:\n",
    "        # Read the pages of each file\n",
    "        full_path = path + row['filename']\n",
    "        fp = open(full_path, 'rb')\n",
    "        \n",
    "        pages = ''\n",
    "\n",
    "        page_no = 0\n",
    "        for pageNumber, page in enumerate(PDFPage.get_pages(fp)):\n",
    "            if pageNumber == page_no:\n",
    "                interpreter.process_page(page)\n",
    "\n",
    "                data = retstr.getvalue().lower()\n",
    "                data = ' ' + data\n",
    "                pages += data\n",
    "                data = ''\n",
    "                retstr.truncate(0)\n",
    "                retstr.seek(0)\n",
    "\n",
    "            page_no += 1\n",
    "            \n",
    "            \n",
    "        # Add citation data to the DataFrame\n",
    "        conn_nodes = list()\n",
    "        \n",
    "        \n",
    "        for title in lda_df['title']:\n",
    "            if title.lower() in pages:\n",
    "                tgt_id = str(lda_df[lda_df['title'] == title].index[0])\n",
    "                if str(i) != tgt_id:\n",
    "                    conn_nodes.append(tgt_id)\n",
    "                    cited_by[tgt_id].append(str(i))\n",
    "                    counter += 1\n",
    "        for author in lda_df['authors abbrev']:\n",
    "            if author.lower() in pages:\n",
    "                tgt_id = str(lda_df[lda_df['authors abbrev'] == author].index[0])\n",
    "                if str(i) != tgt_id:\n",
    "                    conn_nodes.append(tgt_id)\n",
    "                    cited_by[tgt_id].append(str(i))\n",
    "                    counter += 1            \n",
    "        \n",
    "        cite_links.append(\",\".join(conn_nodes))           \n",
    "        \n",
    "    except:\n",
    "        cite_links.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbacc901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logger.info(f\"Setting new columns for citations, journal & publication date\")\n",
    "network_df = lda_df.assign(citations=cite_links)\n",
    "network_df[\"citations\"] = network_df[\"citations\"].fillna(\"\")\n",
    "#network_df = network_df.assign(journal=journals)\n",
    "#network_df = network_df.assign(pub_date=pub_dates)\n",
    "#network_df = network_df.assign(authors=authors)\n",
    "\n",
    "cited_by_list = [\",\".join(cited_by[str(i)]) for i in range(len(network_df))]\n",
    "network_df = network_df.assign(cited_by=cited_by_list)\n",
    "network_df = network_df.assign(\n",
    "    n_cites=[len(i.split(\",\")) if len(i) > 0 else 0 for i in cited_by_list]\n",
    ")\n",
    "\n",
    "for col in [\"title\", \"department\", \"pub_date\", \"authors\", \"authors abbrev\"]:\n",
    "    network_df[col] = network_df[col].fillna(\"No data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83257334",
   "metadata": {},
   "source": [
    "## Output File\n",
    "Before we output the file, I remove the duplicated in the cited by and citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "440a3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates in cited by and citations\n",
    "for i in range(0, network_df.shape[0]):\n",
    "    cited_by = network_df.loc[[i],'cited_by'].values[0]\n",
    "    citations = network_df.loc[[i],'citations'].values[0]\n",
    "    \n",
    "    if cited_by == '':\n",
    "        network_df.loc[[i],'cited_by'] = ''\n",
    "        network_df.loc[[i],'n_cites'] = 0\n",
    "    else:\n",
    "        cited_by = list(set(cited_by.split(',')))\n",
    "        network_df.loc[[i],'cited_by'] = \",\".join(cited_by)\n",
    "        network_df.loc[[i],'n_cites'] = len(cited_by)\n",
    "        \n",
    "    if citations == '':\n",
    "        network_df.loc[[i],'citations'] = ''\n",
    "    else:\n",
    "        citations = list(set(citations.split(',')))\n",
    "        network_df.loc[[i],'citations'] = \",\".join(citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b483e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df_file = \"/Users/marisolhernandez/Desktop/SKAEL/Network Diagram/outputs/network_df.csv\"\n",
    "network_df.to_csv(network_df_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
